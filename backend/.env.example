# LocalAI Document Chat - Environment Configuration
# Copy this file to .env and customize as needed

# Application settings
APP_NAME=LocalAI Document Chat
DEBUG=false

# Ollama settings (local LLM)
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=llama3.2:3b

# Embedding model (runs locally)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Document processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Vector database
CHROMA_PERSIST_DIR=./chroma_db
COLLECTION_NAME=documents

# Upload settings
UPLOAD_DIR=./uploads
MAX_FILE_SIZE_MB=50
